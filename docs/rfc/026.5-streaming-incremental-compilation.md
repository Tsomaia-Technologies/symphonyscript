# RFC-026.5: Streaming & Incremental Compilation

**Status**: Draft  
**Priority**: Medium  
**Estimated Effort**: 5 days  
**Breaking Change**: Internal only  
**Dependencies**: RFC-026 Phases 1-2 (complete)

---

## 1. Purpose

This RFC specifies the detailed algorithms for RFC-026 Phases 3-4:

- **Phase 3**: Streaming compilation via generators
- **Phase 4**: Incremental compilation via section caching

The key blocker from Phase 1-2 analysis: **tie coalescing requires re-sorting**, which breaks streaming. This RFC solves that.

---

## 2. The Tie Coalescing Problem

### Current Behavior

```
Input:  [C4@beat0 tie:start] [C4@beat1 tie:end] [D4@beat0.5]
                                      │
                                      ▼ (process tie:end)
        [C4@beat0 dur:2beats] [D4@beat0.5]  ← WRONG ORDER

Requires re-sort: [D4@beat0.5] [C4@beat0]
```

### Why This Breaks Streaming

Streaming requires emitting in beat order. But tie:end extends the start note's duration retroactively, meaning the final position is known late.

---

## 3. Solution: Deferred Emit with Priority Queue

### Algorithm

```typescript
interface DeferredNote {
  beatStart: number;
  note: TimedPipelineOp;
  tieChain: TimedPipelineOp[]; // Accumulated tied notes
}

function* streamingCoalesce(
  source: Generator<TimedPipelineOp>
): Generator<TimedPipelineOp> {
  // Active ties: key -> deferred note
  const activeTies = new Map<string, DeferredNote>();

  // Priority queue ordered by beatStart (min-heap)
  const readyQueue = new MinHeap<DeferredNote>(
    (a, b) => a.beatStart - b.beatStart
  );

  // Lookahead buffer (notes waiting to see if they're tied)
  const lookahead: TimedPipelineOp[] = [];

  let currentBeat = 0;

  for (const op of source) {
    currentBeat = op.beatStart;

    // Emit anything in readyQueue that's before current beat
    while (!readyQueue.isEmpty() && readyQueue.peek().beatStart < currentBeat) {
      const ready = readyQueue.pop();
      yield finalizeNote(ready);
    }

    if (op.original.kind !== "note") {
      yield op;
      continue;
    }

    const key = tieKey(op.original);
    const tie = op.original.tie;

    if (tie === "start") {
      // Start new tie chain
      activeTies.set(key, {
        beatStart: op.beatStart,
        note: op,
        tieChain: [op],
      });
    } else if (tie === "end" && activeTies.has(key)) {
      // Complete tie chain, push to ready queue
      const deferred = activeTies.get(key)!;
      deferred.tieChain.push(op);
      activeTies.delete(key);
      readyQueue.push(deferred);
    } else if (tie === "continue" && activeTies.has(key)) {
      // Extend tie chain
      activeTies.get(key)!.tieChain.push(op);
    } else {
      // Non-tied note: emit immediately if safe
      yield op;
    }
  }

  // Flush remaining
  for (const deferred of activeTies.values()) {
    readyQueue.push(deferred);
  }
  while (!readyQueue.isEmpty()) {
    yield finalizeNote(readyQueue.pop());
  }
}

function finalizeNote(deferred: DeferredNote): TimedPipelineOp {
  const totalDuration = deferred.tieChain.reduce(
    (sum, op) => sum + op.beatDuration,
    0
  );
  return {
    ...deferred.note,
    beatDuration: totalDuration,
    original: {
      ...deferred.note.original,
      tie: undefined, // Coalesced
    },
  };
}
```

### Key Properties

| Property       | Guarantee                            |
| -------------- | ------------------------------------ |
| **Order**      | Emits in beat-order (priority queue) |
| **Streaming**  | Yields as soon as beat is passed     |
| **Memory**     | O(active ties) not O(total notes)    |
| **No re-sort** | Queue maintains order                |

---

## 4. Generator-Based Pipeline

### Streaming Projections

Each projection becomes a generator:

```typescript
// src/compiler/projections/streaming.ts

export function* streamExpand(
  clip: ClipNode,
  limits: ExpansionLimits
): Generator<PipelineOp> {
  const stack = [{ ops: clip.operations, index: 0, loopCount: 0 }];

  while (stack.length > 0) {
    const frame = stack[stack.length - 1];

    if (frame.index >= frame.ops.length) {
      stack.pop();
      continue;
    }

    const op = frame.ops[frame.index++];

    if (op.kind === "loop") {
      // Push loop expansion onto stack
      for (let i = 0; i < op.times; i++) {
        stack.push({ ops: op.operations, index: 0, loopCount: i });
      }
    } else if (op.kind === "clip") {
      stack.push({ ops: op.clip.operations, index: 0, loopCount: 0 });
    } else {
      yield { kind: "op", original: op };
    }
  }
}

export function* streamTiming(
  source: Generator<PipelineOp>,
  timeSignature: TimeSignatureString
): Generator<TimedPipelineOp> {
  let beat = 0;
  let measure = 1;
  const sigMap = new Map<number, TimeSignatureSegment>();

  for (const op of source) {
    const timed = addTimingInfo(op, beat, measure, sigMap);
    beat += timed.beatDuration;
    yield timed;
  }
}

export function* streamEmit(
  source: Generator<TimedPipelineOp>,
  tempoMap: TempoMap,
  options: EmitOptions
): Generator<CompiledEvent> {
  for (const op of source) {
    yield* emitOperation(op, tempoMap, options);
  }
}
```

### Composed Streaming Pipeline

```typescript
export function* compileClipStreaming(
  clip: ClipNode,
  options: PipelineConfig
): Generator<CompiledEvent> {
  const expanded = streamExpand(clip, options);
  const timed = streamTiming(expanded, options.timeSignature);

  // Build tempo map (still needs lookahead for tempo changes)
  const tempoMap = buildTempoMap(timed);

  // Reset and reprocess with tempo map
  const expandedAgain = streamExpand(clip, options);
  const timedAgain = streamTiming(expandedAgain, options.timeSignature);
  const coalesced = streamingCoalesce(timedAgain);

  yield* streamEmit(coalesced, tempoMap, options);
}
```

---

## 5. Incremental Compilation

### Section Boundary Detection

Sections are natural break points where state can be snapshotted:

```typescript
interface SectionBoundary {
  beatPosition: number;
  hash: string; // Content hash of section
  stateSnapshot: ProjectionState;
}

interface ProjectionState {
  beat: number;
  measure: number;
  bpm: number;
  timeSignature: TimeSignatureString;
  transposition: number;
  dynamicsLevel: number;
  activeTies: Map<string, DeferredNote>;
}
```

### Content Hashing

```typescript
import { createHash } from "crypto";

function hashSection(operations: ClipOperation[]): string {
  const content = JSON.stringify(operations); // Deterministic
  return createHash("sha256").update(content).digest("hex").slice(0, 16);
}

function detectSections(clip: ClipNode): Section[] {
  const sections: Section[] = [];
  let currentBeat = 0;

  for (const op of clip.operations) {
    if (isSectionBoundary(op)) {
      sections.push({
        startBeat: currentBeat,
        operations: [],
        hash: "",
      });
    }
    sections[sections.length - 1].operations.push(op);
    currentBeat += getDuration(op);
  }

  // Hash each section
  for (const section of sections) {
    section.hash = hashSection(section.operations);
  }

  return sections;
}

function isSectionBoundary(op: ClipOperation): boolean {
  // Section boundaries at:
  return (
    op.kind === "tempo" || // Tempo changes
    op.kind === "timeSignature" || // Time signature changes
    op.kind === "marker"
  ); // Explicit markers
}
```

### Incremental Recompilation

```typescript
interface CompilationCache {
  sections: CachedSection[];
  finalState: ProjectionState;
}

interface CachedSection {
  hash: string;
  events: CompiledEvent[];
  startBeat: number;
  endBeat: number;
  endState: ProjectionState;
}

function incrementalCompile(
  clip: ClipNode,
  previousCache: CompilationCache,
  options: PipelineConfig
): { events: CompiledEvent[]; cache: CompilationCache } {
  const newSections = detectSections(clip);
  const result: CompiledEvent[] = [];
  const newCache: CachedSection[] = [];

  let currentState: ProjectionState | null = null;

  for (let i = 0; i < newSections.length; i++) {
    const section = newSections[i];
    const cached = previousCache.sections[i];

    if (cached && cached.hash === section.hash && currentState === null) {
      // Cache hit: reuse events
      result.push(...cached.events);
      newCache.push(cached);
      currentState = cached.endState;
    } else {
      // Cache miss: recompile from this point
      const startState = currentState ?? initialProjectionState(options);
      const compiled = compileSection(section, startState, options);

      result.push(...compiled.events);
      newCache.push({
        hash: section.hash,
        events: compiled.events,
        startBeat: section.startBeat,
        endBeat: section.startBeat + section.durationBeats,
        endState: compiled.endState,
      });
      currentState = compiled.endState;
    }
  }

  return {
    events: result,
    cache: { sections: newCache, finalState: currentState! },
  };
}
```

---

## 6. Files to Create/Modify

| Action | Path                                          | Description                 |
| ------ | --------------------------------------------- | --------------------------- |
| ADD    | `src/compiler/projections/streaming.ts`       | Generator-based projections |
| ADD    | `src/compiler/projections/coalesce-stream.ts` | Streaming tie coalescing    |
| ADD    | `src/compiler/projections/cache.ts`           | Section caching logic       |
| ADD    | `src/compiler/projections/hash.ts`            | Content hashing             |
| MODIFY | `src/compiler/projections/compose.ts`         | Add streaming compose       |
| MODIFY | `src/compiler/projections/index.ts`           | Export new functions        |

---

## 7. Testing Strategy

```typescript
describe("Streaming Compilation", () => {
  it("produces identical output to batch compilation", () => {
    const clip = createComplexClip();

    const batchResult = [...compileClipV2(clip, options).events];
    const streamResult = [...compileClipStreaming(clip, options)];

    expect(streamResult).toEqual(batchResult);
  });

  it("yields events in beat order", () => {
    const clip = createTiedClip();
    const events = [...compileClipStreaming(clip, options)];

    for (let i = 1; i < events.length; i++) {
      expect(events[i].startSeconds).toBeGreaterThanOrEqual(
        events[i - 1].startSeconds
      );
    }
  });
});

describe("Incremental Compilation", () => {
  it("reuses cached sections on unchanged content", () => {
    const clip1 = createClip();
    const result1 = incrementalCompile(clip1, emptyCache, options);

    const clip2 = sameClip(); // Identical content
    const result2 = incrementalCompile(clip2, result1.cache, options);

    expect(result2.events).toEqual(result1.events);
    // Verify cache was used (no recompilation)
  });

  it("recompiles only changed sections", () => {
    const clip1 = Clip.melody()
      .note("C4")
      .note("D4") // Section 1
      .tempo(140)
      .note("E4")
      .note("F4") // Section 2
      .build();

    const result1 = incrementalCompile(clip1, emptyCache, options);

    const clip2 = Clip.melody()
      .note("C4")
      .note("D4") // Section 1 (unchanged)
      .tempo(140)
      .note("G4")
      .note("A4") // Section 2 (changed)
      .build();

    // Only section 2 should be recompiled
    const result2 = incrementalCompile(clip2, result1.cache, options);

    expect(result2.cache.sections[0].hash).toBe(result1.cache.sections[0].hash);
    expect(result2.cache.sections[1].hash).not.toBe(
      result1.cache.sections[1].hash
    );
  });
});
```

---

## 8. Performance Targets

| Metric              | Batch | Streaming      | Incremental (1% change) |
| ------------------- | ----- | -------------- | ----------------------- |
| Traversals          | 1     | 1              | 0.05 (5% of clip)       |
| Memory peak         | O(n)  | O(active ties) | O(changed section)      |
| Time to first event | O(n)  | O(1)           | O(1)                    |

---

## 9. Approval

- [ ] Approved by maintainer
